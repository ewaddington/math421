
---
output: 
  html_document:
  pdf_document: default
  word_document: default
title: "Assignment 10: Predictive Modeling - Part 1"
---

***How to do it?***: 

- Open the Rmarkdown file of this assignment ([link](assignment10.Rmd)) in Rstudio. 

- Right under each **question**, insert  a code chunk (you can use the hotkey `Ctrl + Alt + I` to add a code chunk) and code the solution for the question. 

- `Knit` the rmarkdown file (hotkey: `Ctrl + Alt + K`) to export an html.  

-  Publish the html file to your Githiub Page. 

***Submission***: Submit the link on Github of the assignment to Canvas

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE)
```


-------

1. Use the `Adult Census Income` dataset.  We will predict the income (whether or not it is more than 50k or not) of an adult. Import the dataset.  Partition the data into 80% training and 20% testing.  
```{r}
library(tidyverse)
library(rattle)
library(rpart)
library(randomForest)
library(caret)
library(caTools)

```
```{r}
df <- read.csv("adult_census_missing.csv")
```
```{r}
df <- na.omit(df) 
df$income <- factor(df$income, levels = c("<=50K", ">50K"))
```
```{r}
set.seed(123)
split <- sample.split(df$income, SplitRatio = 0.8)
train <- subset(df, split == TRUE)
test <- subset(df, split == FALSE)
```



2. Practice Decision Tree.  Do the follows:

  - Use `rpart` package, create a decision tree with maximum depth of 3. 
  
  - Calculate the accuracy of the model on the testing data. Notice that the positive outcome here is not `1` but `>50K` or `<50K`. 
  
  - Plot the tree
  
  - Plot the variable importance by the tree
```{r}
tree1 <- rpart(income ~ ., data = train, method = "class", control = rpart.control(maxdepth = 3))
pred_tree1 <- predict(tree1, test, type = "class")
accuracy_tree1 <- sum(pred_tree1 == test$income) / nrow(test)
print(paste("Decision Tree (Depth=3) Accuracy:", round(accuracy_tree1, 4)))
```
```{r}
plot(tree1)
text(tree1)
```
```{r}
var_importance_tree <- tree1$variable.importance 
barplot(var_importance_tree, 
        main = "Variable Importance by Tree", 
        xlab = "Variables", 
        ylab = "Importance", 
        col = "lightblue", 
        las = 2)
```
  
  
3. Create 3 more trees and compare the testing accuracy of these trees, which tree give the highest testing accuracy.
```{r}
tree2 <- rpart(income ~ ., data = train, method = "class", control = rpart.control(maxdepth = 5))
pred_tree2 <- predict(tree2, test, type = "class")
accuracy_tree2 <- sum(pred_tree2 == test$income) / nrow(test)
```


```{r}
tree3 <- rpart(income ~ ., data = train, method = "class", control = rpart.control(minsplit = 20))
pred_tree3 <- predict(tree3, test, type = "class")
accuracy_tree3 <- sum(pred_tree3 == test$income) / nrow(test)
```


```{r}
tree4 <- rpart(income ~ ., data = train, method = "class", control = rpart.control(cp = 0.01))
pred_tree4 <- predict(tree4, test, type = "class")
accuracy_tree4 <- sum(pred_tree4 == test$income) / nrow(test)
```
```{r}
tree_accuracies <- c(accuracy_tree1, accuracy_tree2, accuracy_tree3, accuracy_tree4)
names(tree_accuracies) <- c("Tree1", "Tree2", "Tree3", "Tree4")
print(tree_accuracies)
```


4. Practice Random Forest.  Do the follows: 

  - Use `randomForest` package, create a random forest of 1000 trees. 
  
  - Calculate the accuracy of the model on the testing data. 
  
  - Plot the variable importance by the forest
```{r}
rf1 <- randomForest(income ~ ., data = train, ntree = 1000)
pred_rf1 <- predict(rf1, test)
accuracy_rf1 <- sum(pred_rf1 == test$income) / nrow(test)
print(paste("Random Forest (1000 Trees) Accuracy:", round(accuracy_rf1, 4)))
```
```{r}
varImpPlot(rf1, main = "Variable Importance by Random Forest")
```
  

5. Create 3 more forests and compare the testing accuracy of these forests, which forest give the highest testing accuracy.
```{r}
library(randomForest)

rf2 <- randomForest(income ~ ., data = train, ntree = 500)
pred_rf2 <- predict(rf2, test)
accuracy_rf2 <- sum(pred_rf2 == test$income) / nrow(test)
```


```{r}
rf3 <- randomForest(income ~ ., data = train, ntree = 1500)
pred_rf3 <- predict(rf3, test)
accuracy_rf3 <- sum(pred_rf3 == test$income) / nrow(test)
```


```{r}
rf4 <- randomForest(income ~ ., data = train, ntree = 1000, mtry = 3)
pred_rf4 <- predict(rf4, test)
accuracy_rf4 <- sum(pred_rf4 == test$income) / nrow(test)

```
```{r}
forest_accuracies <- c(accuracy_rf1, accuracy_rf2, accuracy_rf3, accuracy_rf4)
names(forest_accuracies) <- c("RF1 (1000 trees)", "RF2 (500 trees)", "RF3 (1500 trees)", "RF4 (mtry=3)")
print("Testing Accuracies of Random Forests:")
print(forest_accuracies)
```


6. What is the best model (in term of testing accuracy) among all models (including trees and forests) you have trained?
```{r}
best_forest <- names(forest_accuracies)[which.max(forest_accuracies)]
best_accuracy <- max(forest_accuracies)

cat("The best random forest model is", best_forest, "with an accuracy of", round(best_accuracy, 4), "\n")
```


